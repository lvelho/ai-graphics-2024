{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lvelho/ai-graphics-2024/blob/main/assignments/notebooks/deforming_meshes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1OFkszp0oc-"
      },
      "source": [
        "#  AI Graphics | NYU 2024\n",
        "### Instructor: Luiz Velho\n",
        "\n",
        "## Assignment - Deform a source mesh to form a target mesh using 3D loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-h1ji4dWHQ5"
      },
      "source": [
        "## 0. Install and Import modules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7JS4K6d0Jy7"
      },
      "source": [
        "Ensure `torch` and `torchvision` are installed. If `pytorch3d` is not installed, install it using the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qkuyhyTeRyM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith((\"2.2.\")) and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        !pip install fvcore iopath\n",
        "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylbZGXYBtuvB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from pytorch3d.io import load_obj, save_obj\n",
        "from pytorch3d.structures import Meshes\n",
        "from pytorch3d.utils import ico_sphere\n",
        "from pytorch3d.ops import sample_points_from_meshes\n",
        "from pytorch3d.loss import (\n",
        "    chamfer_distance, \n",
        "    mesh_edge_loss, \n",
        "    mesh_laplacian_smoothing, \n",
        "    mesh_normal_consistency,\n",
        ")\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "%matplotlib notebook \n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['savefig.dpi'] = 80\n",
        "mpl.rcParams['figure.dpi'] = 80\n",
        "\n",
        "# Set the device\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"WARNING: CPU only, this will be slow!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT1JTXu1WHQ_"
      },
      "source": [
        "## 1. Load an obj file and create a Meshes object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTPzfi8_0Jy9"
      },
      "source": [
        "Download the target 3D model of a dolphin. It will be saved locally as a file called `dolphin.obj`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFNkB6nQWZSw"
      },
      "outputs": [],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/pytorch3d/data/dolphin/dolphin.obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dz0imH-ltuvS"
      },
      "outputs": [],
      "source": [
        "# Load the dolphin mesh.\n",
        "trg_obj = os.path.join('dolphin.obj')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbyRhI8ituvW"
      },
      "outputs": [],
      "source": [
        "# We read the target 3D model using load_obj\n",
        "verts, faces, aux = load_obj(trg_obj)\n",
        "\n",
        "# verts is a FloatTensor of shape (V, 3) where V is the number of vertices in the mesh\n",
        "# faces is an object which contains the following LongTensors: verts_idx, normals_idx and textures_idx\n",
        "# For this tutorial, normals and textures are ignored.\n",
        "faces_idx = faces.verts_idx.to(device)\n",
        "verts = verts.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St_f2PKAcGV_"
      },
      "outputs": [],
      "source": [
        "# We initialize the source shape to be a sphere of radius 1\n",
        "src_mesh = ico_sphere(4, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrzlhtbFaXSN"
      },
      "source": [
        "1.1 The source mesh is a sphere of radius 1 centered at (0, 0, 0). To speed up the optimization process, we should scale normalize the target mesh and center it at the origin, making it fit the unit sphere. Do this operations with the `verts`tensor and create a `Meshes` object called \"trg_mesh\" with the normalized vertices and the faces indices.\n",
        "\n",
        "1.2 Visualize the source and target meshes using `Plotly` integration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyOFi-7taWq5"
      },
      "outputs": [],
      "source": [
        "##############################################################################\n",
        "# Code for 1.1 - 1.2\n",
        "##############################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYWDl4VGWHRK"
      },
      "source": [
        "###  Visualizing point clouds with Matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geI4FTtwdxsq"
      },
      "source": [
        "We can also sample points from the surfaces and visualize them using Matplotlib. It can be a useful to have a coarse estimation of the surface during iterations in the optimization process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "482YycLHWHRL"
      },
      "outputs": [],
      "source": [
        "def plot_pointcloud(mesh, title=\"\"):\n",
        "    # Sample points uniformly from the surface of the mesh.\n",
        "    points = sample_points_from_meshes(mesh, 5000)\n",
        "    x, y, z = points.clone().detach().cpu().squeeze().unbind(1)    \n",
        "    fig = plt.figure(figsize=(5, 5))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "    ax.scatter3D(x, z, -y)\n",
        "    ax.set_xlabel('x')\n",
        "    ax.set_ylabel('z')\n",
        "    ax.set_zlabel('y')\n",
        "    ax.set_title(title)\n",
        "    ax.view_init(190, 30)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86dQA5w4dbcg"
      },
      "source": [
        "1.3 Use the function `plot_pointcloud` to see the initial pointcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UoGcflJ_WHRO"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "##############################################################################\n",
        "# Code for 1.3\n",
        "##############################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uzMiTUSWHRS"
      },
      "source": [
        "## 2. Optimization loop "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekMWSPBOffI1"
      },
      "source": [
        "Starting from a sphere mesh, we learn the offset to each vertex in the mesh such that the predicted mesh is closer to the target mesh at each optimization step. To achieve this we minimize the distance between the predicted (deformed) and target mesh, defined as the **chamfer distance** between the set of pointclouds resulting from **differentiably sampling points** from their surfaces.\n",
        "\n",
        "However, solely minimizing the chamfer distance between the predicted and the target mesh will lead to a non-smooth shape. We enforce smoothness by adding **shape regularizers** to the objective. Namely, we add:\n",
        "\n",
        "+ `mesh_edge_length`, which minimizes the length of the edges in the predicted mesh.\n",
        "+ `mesh_normal_consistency`, which enforces consistency across the normals of neighboring faces.\n",
        "+ `mesh_laplacian_smoothing`, which is the laplacian regularizer.\n",
        "We will learn to deform the source mesh by offsetting its vertices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sc-3M17Ltuvh"
      },
      "outputs": [],
      "source": [
        "# The shape of the deform parameters is equal to the total number of vertices in src_mesh\n",
        "deform_verts = torch.full(src_mesh.verts_packed().shape, 0.0, device=device, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BtSUfMYtuvl"
      },
      "outputs": [],
      "source": [
        "# The optimizer\n",
        "optimizer = torch.optim.SGD([deform_verts], lr=1.0, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OBS: Note that you need the \"trg_mesh\" from 1.1 for the optimization code to work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Number of optimization steps\n",
        "Niter = 2000\n",
        "# Weight for the chamfer loss\n",
        "w_chamfer = 1.0 \n",
        "# Weight for mesh edge loss\n",
        "w_edge = 1.0 \n",
        "# Weight for mesh normal consistency\n",
        "w_normal = 0.01 \n",
        "# Weight for mesh laplacian smoothing\n",
        "w_laplacian = 0.1 \n",
        "# Plot period for the losses\n",
        "plot_period = 250\n",
        "loop = tqdm(range(Niter))\n",
        "\n",
        "chamfer_losses = []\n",
        "laplacian_losses = []\n",
        "edge_losses = []\n",
        "normal_losses = []\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "for i in loop:\n",
        "    # Initialize optimizer\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Deform the mesh\n",
        "    new_src_mesh = src_mesh.offset_verts(deform_verts)\n",
        "    \n",
        "    # We sample 5k points from the surface of each mesh \n",
        "    sample_trg = sample_points_from_meshes(trg_mesh, 5000)\n",
        "    sample_src = sample_points_from_meshes(new_src_mesh, 5000)\n",
        "    \n",
        "    # We compare the two sets of pointclouds by computing (a) the chamfer loss\n",
        "    loss_chamfer, _ = chamfer_distance(sample_trg, sample_src)\n",
        "    \n",
        "    # and (b) the edge length of the predicted mesh\n",
        "    loss_edge = mesh_edge_loss(new_src_mesh)\n",
        "    \n",
        "    # mesh normal consistency\n",
        "    loss_normal = mesh_normal_consistency(new_src_mesh)\n",
        "    \n",
        "    # mesh laplacian smoothing\n",
        "    loss_laplacian = mesh_laplacian_smoothing(new_src_mesh, method=\"uniform\")\n",
        "    \n",
        "    # Weighted sum of the losses\n",
        "    loss = loss_chamfer * w_chamfer + loss_edge * w_edge + loss_normal * w_normal + loss_laplacian * w_laplacian\n",
        "    \n",
        "    # Print the losses\n",
        "    loop.set_description('total_loss = %.6f' % loss)\n",
        "    \n",
        "    # Save the losses for plotting\n",
        "    chamfer_losses.append(float(loss_chamfer.detach().cpu()))\n",
        "    edge_losses.append(float(loss_edge.detach().cpu()))\n",
        "    normal_losses.append(float(loss_normal.detach().cpu()))\n",
        "    laplacian_losses.append(float(loss_laplacian.detach().cpu()))\n",
        "    \n",
        "    # Plot mesh\n",
        "    if i % plot_period == 0:\n",
        "        plot_pointcloud(new_src_mesh, title=\"iter: %d\" % i)\n",
        "        \n",
        "    # Optimization step\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGcZsvWBWHRc"
      },
      "source": [
        "## Visualize the loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87EjaDxZPWsM"
      },
      "outputs": [],
      "source": [
        "def plot_losses(loss_dict, size=(13,5)):\n",
        "  fig = plt.figure(figsize=size)\n",
        "  ax = fig.gca()\n",
        "  for loss_name, loss_values in loss_dict.items():\n",
        "    ax.plot(loss_values, label=loss_name)\n",
        "  ax.legend(fontsize=\"16\")\n",
        "  ax.set_xlabel(\"Iteration\", fontsize=\"16\")\n",
        "  ax.set_ylabel(\"Loss\", fontsize=\"16\")\n",
        "  ax.set_title(\"Loss vs iterations\", fontsize=\"16\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRmLaLz-P9bN"
      },
      "outputs": [],
      "source": [
        "losses = {\"chamfer loss\": chamfer_losses, \n",
        "          \"edge loss\": edge_losses,\n",
        "          \"normal loss\": normal_losses,\n",
        "          \"laplacian loss\": laplacian_losses}\n",
        "plot_losses(losses, (18, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9vSKErDWHRg"
      },
      "source": [
        "## Save the predicted mesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frNTBwhRh3Av"
      },
      "outputs": [],
      "source": [
        "# Fetch the verts and faces of the final predicted mesh\n",
        "final_verts, final_faces = new_src_mesh.get_mesh_verts_faces(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd4b7fXRh0fx"
      },
      "source": [
        "2.1 Scale normalize back the `final_verts` to the original target size\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iq6_CP9IiEBm"
      },
      "outputs": [],
      "source": [
        "##############################################################################\n",
        "# Code for 2.1\n",
        "##############################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krikJzrLtuvw"
      },
      "outputs": [],
      "source": [
        "# Store the predicted mesh using save_obj\n",
        "final_obj = os.path.join('./', 'final_model.obj')\n",
        "save_obj(final_obj, final_verts, final_faces)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omv3QtjcRH6r"
      },
      "source": [
        "2.2 Visualize the target mesh and the final mesh using `Plotly`. Qualitatively, what do you think of the result?\n",
        "\n",
        "2.3 Take a look at the **Loss vs Iteration** graph, paying attention to how the losses are decreasing. Do you think it would be possible to achieve a reasonable result with less iterations? Is it worth to run with more iterations? Explain you thoughts, then run the optimization loop again making the changes to validate your hypothesis.\n",
        "\n",
        "2.4 The loss function used for this task is a linear combination of four losses. Let `w_chamfer = 1.0` and set the other coefficients to zero. Run the  optimization loop again with this configuration and describe the result. \n",
        "\n",
        "**[EXTRA] E.1 Experiment other coefficients configurations and describe the results.**\n",
        "\n",
        "2.5 Experiment with others optimizers such as `Adam` and `RMSprop` in place of `SGD`. Also, try changing the learning rate (`lr`), and `momentum` when these parameters are applied. What do you observe in terms of speed of convergence and quality of final results?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4kRPbgftz1u"
      },
      "outputs": [],
      "source": [
        "##############################################################################\n",
        "# Code for 2.1 - 2.5\n",
        "##############################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S13xm7HecK1h"
      },
      "source": [
        "# 3. Experimenting with Other Shapes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pt9CcWX2uGhP"
      },
      "outputs": [],
      "source": [
        "# download the mug model - Mug by Microsoft is licensed under Creative Commons Attribution\n",
        "# originally found at https://sketchfab.com/3d-models/mug-17c4808537f1448590378b3643c6da72\n",
        "!wget https://raw.githubusercontent.com/hallpaz/3dsystems21/main/data/mug.obj"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AjX0f9JcM73"
      },
      "source": [
        "3.1 Is it possible to deform any mesh into another? Explain your thoughts.\n",
        "\n",
        "3.2 Run the experiment again and try to deform a sphere into a mug.\n",
        "\n",
        "3.3 Change the `src_mesh` to a `torus`. You can import the torus primitive from `pytorch3d.utils`. Now, try to deform the torus into a mug.\n",
        "\n",
        "\n",
        "**[Extra] E.2 Run the experiments again using other shapes (either find and download shapes from the internet or create your own models).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd6zc5Fetwcy"
      },
      "outputs": [],
      "source": [
        "##############################################################################\n",
        "# Code for 3.1 - 3.3\n",
        "##############################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TVFzxPT_tWL"
      },
      "source": [
        "# 4. Food for Thoughts\n",
        "\n",
        "Let's say you have a big set Ω of arbitrary meshes, and 1 mesh or a small set Δ of meshes, for example from the same class, that you are instered in. How would you solve the problem of fitting meshes from Ω to meshes in Δ? "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
