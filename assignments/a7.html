<HTML>
<HEAD>

<TITLE>Assignment 7</TITLE>

</HEAD>

<BODY>

<HR>

<H1>Assignment 7</H1>

<p>In this assignment, we will load a textured mesh from an obj file, create a synthetic dataset by rendering the mesh from multiple viewpoints and use our multi-view dataset to infer properties of the scene with a differentiable renderer. First, we’ll set up an optimization loop to fit a mesh to the observed dataset images based on a rendered silhouette loss; then we will augment this optimization loop with an additional loss based on rendered RGB images, aiming to predict both a mesh and its texture; and finally we’ll learn to infer the camera position of a rendered image using the mesh geometry.</p>

<p><strong>The goals of this practice are the following:</strong></p>

<ul>
  <li>Create a synthetic dataset by rendering a textured mesh from multiple viewpoints</li>
  <li>Understand more deeply a renderer pipeline</li>
  <li>Learn how a differentiable pipeline can be used to infer a variety of scene properties</li>
  <li>Train a model to infer 3D geometry using 2D images supervision</li>
  <li>Test and understand the limitations of a differentiable renderer</li>
</ul>

<h2 id="instructions">Notebook:</h2>

<p>Assignment 13 Notebook
<a href="https://colab.research.google.com/github/lvelho/ai-graphics-2024/blob/main/assignments/notebooks/mesh_texture_camera.ipynb" target="_blank"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></p>

<h3 id="submission">Submission</h3>

<p>The assignment is due on May 29th, 2024 at 11:59pm (EDT).</p>

<h3 id="references">References:</h3>

<ol>
  <li>PyTorch3D: <a href="https://pytorch3d.org/docs/renderer_getting_started">Getting Started with Renderer</a></li>
</ol>


<HR>

</BODY>
</HTML>
